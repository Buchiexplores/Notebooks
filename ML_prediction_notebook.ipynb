{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_prediction_notebook",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMeW6NZiHLFH6gAWGeuNECA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Buchiexplores/Notebooks/blob/master/ML_prediction_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzVfSiFaeblu",
        "colab_type": "text"
      },
      "source": [
        "##**PYTHON NOTEBOOK ON PROTOTYPING MACHINE LEARNING PREDICTION MODELS**\n",
        "Written and compiled by **Abuchi Godswill Okeke**\n",
        "\n",
        "Linkedin: https://www.linkedin.com/in/abuchi-okeke-67b48a105/\n",
        "\n",
        "e-mail: abuchi.okeke@uky.edu\n",
        "\n",
        "#Features:\n",
        "* Upload files from google drive or local device drive\n",
        "* Dimensional reduction and feature selection using PCA\n",
        "* Cross-Validation to find best estimators\n",
        "* Random forest Regressor\n",
        "* K nearest neighbor Regressor\n",
        "* Decision trees Regressor\n",
        "* Support vector Regressor\n",
        "* Partial Least Square Regression (PLSR)\n",
        "* Ensemble learning\n",
        "* Model evaluation (Validation curves, R_Squarred and RMSE)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPu3l5HFSDJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing data from local drive\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import validation_curve\n",
        "from yellowbrick.datasets import load_energy\n",
        "from yellowbrick.model_selection import ValidationCurve\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "\n",
        "# Plotting library\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D  # needed to plot 3-D surfaces\n",
        "\n",
        "# tells matplotlib to embed plots within the notebook\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrWsT4p_HCne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1KEfi5l6uE1iCcaxPlFozjrx3EBG40iwb'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('classification_resampled.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8nAe961ciEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uploaded = files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0VdtFqUf2Xl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#label_df = pd.read_csv(io.BytesIO(uploaded['Yclassification_label.csv']))\n",
        "# Dataset is n#ow stored in a Pandas Dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOFcNqE2vlcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/content/';"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCUy_LzDvOF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.loadtxt(base_dir + 'bread_samples.csv', delimiter=',');\n",
        "y = np.loadtxt(base_dir + 'Ylabel.csv');\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl8fxthSGF7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wavenumbers = np.loadtxt(base_dir + 'bread_wavenumbers.csv', delimiter=',');\n",
        "np.transpose(wavenumbers)[1].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pohG88slGaUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Visualize data\n",
        "plt.figure()\n",
        "plt.gca().invert_xaxis()\n",
        "plt.plot(np.transpose(wavenumbers)[1],data, '-')\n",
        "plt.xlabel('Wavenumbers')\n",
        "plt.ylabel('Absorbances')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cExyKJrwf_zv",
        "colab_type": "text"
      },
      "source": [
        "#Dimensional reduction and feature selection using **PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_PmLKCSKbUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PCA Dimensional Reduction\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ug058sXKlGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standardize the feature matrix\n",
        "#data_rescaled = StandardScaler().fit_transform(data)\n",
        "#data = np.transpose(data)\n",
        "scaler = MinMaxScaler(feature_range=[0, 1])\n",
        "data_rescaled = scaler.fit_transform(np.transpose(data))\n",
        "data_rescaled.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUpZ-Hd00xz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fit PCA\n",
        "pca = PCA().fit(data_rescaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKJM1i_oyQY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plotting the Cumulative Summation of the Explained Variance\n",
        "plt.figure()\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Variance (%)') #for each component\n",
        "plt.title('Pulsar Dataset Explained Variance')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z17kPtyOKqqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a PCA that will retain 99% of the variance\n",
        "pca = PCA(n_components=30, whiten=True)\n",
        "\n",
        "#Conduct PCA\n",
        "data_pca = pca.fit_transform(data_rescaled)\n",
        "#wavenumbers_pca = pca.fit_transform(np.transpose(wavenumbers))\n",
        "data_pca"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-THyJ8TkKr3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Show results\n",
        "print('Original number of features:', data_rescaled.shape)\n",
        "print('Reduced number of features:', data_pca.shape)\n",
        "print('Number of labels:', y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIs3xq0rBStu",
        "colab_type": "text"
      },
      "source": [
        "##**Data Splitting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ0p2s28pBeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sample, test_sample, train_label, test_label = train_test_split(data_pca, y, train_size=0.8,\n",
        "        test_size=0.2, \n",
        "        # random but same for all run, also accuracy depends on the\n",
        "        # selection of data e.g. if we put 10 then accuracy will be 1.0\n",
        "        # in this example\n",
        "        random_state=42\n",
        "        # keep same proportion of 'target' in test and target data\n",
        "        # stratify=targets  # can not used for single feature\n",
        "        )\n",
        "\n",
        "train_sample_plsr, test_sample_plsr, train_label_plsr, test_label_plsr = train_test_split(data_rescaled, y, train_size=0.8,\n",
        "        test_size=0.2, random_state=42)\n",
        "print(train_sample.shape)\n",
        "print(test_sample.shape)\n",
        "print(train_label.shape)\n",
        "print(test_label.shape)\n",
        "train_sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUKn-fWT0QRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Visualize data\n",
        "#plt.figure()\n",
        "#plt.plot(data, np.transpose(y), '.')\n",
        "#plt.xlabel('Data');\n",
        "#plt.ylabel('labels')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2drZUzTLqcI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Visualize data\n",
        "#plt.figure()\n",
        "#plt.plot(data_pca, np.transpose(y), '.')\n",
        "#plt.xlabel('Data');\n",
        "#plt.ylabel('labels')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQQnAeFMR9r7",
        "colab_type": "text"
      },
      "source": [
        "##**Validation Curve Function**\n",
        "\n",
        "Tunning the hyper-parameters of each estimators help to determine how well our learning algorithm performs. The function below validates the learning scores against any given range of estimator parameter. If the training score and the validation score are both low, the estimator will be underfitting. If the training score is high and the validation score is low, the estimator is overfitting and otherwise it is working very well. A low training score and a high validation score is usually not possible. All three cases can be observed using the function below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51I3BEBJuzjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def validate_estimator (X,y,estimator,estimator_name,para_name,para_range,x_label):\n",
        " \n",
        "  #scoring=\"neg_mean_squared_error\"\n",
        "  train_scores, test_scores = validation_curve(estimator, X, y, param_name=para_name,scoring=\"r2\",param_range=para_range,cv=5)\n",
        "  train_scores_mean = np.mean((1+train_scores), axis=1)\n",
        "  train_scores_std = np.std((1+train_scores), axis=1)\n",
        "  test_scores_mean = np.mean((1+test_scores), axis=1)\n",
        "  test_scores_std = np.std((1+test_scores), axis=1)\n",
        "\n",
        "  plt.title(\"Validation Curve for %s\" % estimator_name)\n",
        "  plt.xlabel(\"%s\" % x_label)\n",
        "  plt.ylabel(\"Score\")\n",
        "  plt.ylim(0.0, 3)\n",
        "  lw = 2\n",
        "  plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
        "             color=\"darkorange\", lw=lw)\n",
        "  plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
        "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
        "                 color=\"darkorange\", lw=lw)\n",
        "  plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
        "             color=\"navy\", lw=lw)\n",
        "  plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
        "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
        "                 color=\"navy\", lw=lw)\n",
        "  plt.legend(loc=\"best\")\n",
        "  return plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93i-ZyEcuot4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def yellow_validate(X,y,estimator,para_name,param_range):\n",
        "\n",
        "#   viz = ValidationCurve(\n",
        "#     estimator, param_name=para_name,\n",
        "#     param_range=param_range, cv=10, scoring=\"r2\"\n",
        "#   )\n",
        "\n",
        "#   # Fit and show the visualizer\n",
        "#   viz.fit(X, y)\n",
        "#   return viz.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9Nd3ByuTlFj",
        "colab_type": "text"
      },
      "source": [
        "#**Parameter Search:**\n",
        "Loops through range of parameters using cross-validation to obtain the value with minimum  mean squared error (optimal parameter).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T4EAHlPJYfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cross-validation\n",
        "#find the best n_estimators\n",
        "\n",
        "estimators = list(range(1, 1000,10))\n",
        "#estimators = list(np.arange(0.0001,0.001,0.0001))\n",
        "# empty list that will hold cv scores\n",
        "cv_scores = []\n",
        "cv_r2 = []\n",
        "\n",
        "# perform 10-fold cross validation\n",
        "for k in estimators:\n",
        "    Rf = RandomForestRegressor(n_estimators=k, criterion='mse', max_depth=k, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=False, oob_score=False, n_jobs=-1, random_state=500, verbose=0, warm_start=False)\n",
        "\n",
        "    #scores = cross_val_score(Rf, train_sample, train_label.ravel(), scoring=('r2','neg_mean_squared_error'), cv=10)\n",
        "    scores_cv = cross_validate(Rf, train_sample, train_label, groups=None, scoring=('r2','neg_mean_squared_error'), cv=10, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=True, return_estimator=False)\n",
        "    print(scores_cv['test_neg_mean_squared_error'])\n",
        "    print(scores_cv['train_r2'])\n",
        "    cv_r2.append(scores_cv['train_r2'].mean())\n",
        "    cv_scores.append(np.mean(list(scores_cv.values())))\n",
        "    #cv_scores.append(scores_cv.mean())\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZJp1ldgGehH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# changing to misclassification error\n",
        "mse = [1 - x for x in cv_scores]\n",
        "\n",
        "# determining best k\n",
        "optimal_k = estimators[mse.index(min(mse))]\n",
        "opt_r2 = cv_r2[mse.index(min(mse))]\n",
        "print(\"The optimal number of estimators is {}\".format(optimal_k))\n",
        "print(\"The R_Squared for optimal number of estimator is {}\".format(opt_r2))\n",
        "\n",
        "# plot misclassification error vs k\n",
        "plt.plot(estimators, mse)\n",
        "plt.xlabel(\"Number of Estimators K\")\n",
        "plt.ylabel(\"Misclassification Error\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_fkoF81YqHC",
        "colab_type": "text"
      },
      "source": [
        "#**Learning Algorithms**\n",
        "Random forest, K-nearest neighbors, Decision tree, support vector machine and ensemble learning (Voting method). The ensemble method is use depending on the performance of individual learning algorithm. If a single learning algorithm outperfoms others, the use of the ensemble method will be ignored.\n",
        "\n",
        "\n",
        "#**Model Evaluation**\n",
        "* RMSE\n",
        "* R_Squared\n",
        "* Validation curve\n",
        "\n",
        "The test data indicates how well your model has generalized. The test data is use to validate how good your model is.\n",
        "\n",
        "Using machine learning method, it is very common to present both the validation and the test accuracy (R_Squared), but the most important is the test accuracy.\n",
        "\n",
        "During the process of training and you get a significant lower 𝑅2 score on test, and not the training, then something is not adding up. If the 𝑅2test is far less than 𝑅2 training, then it indicates that your model does not generalize well. That is, if you subject your model to future test set data points it would not extrapolate very well and thus, the performance of the model will be poor.  \n",
        "\n",
        "**In conclusion:** focus should be on the result from the test set scores/accuracy/R_squared rather than that of the training set.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84tIq9E9Z4e4",
        "colab_type": "text"
      },
      "source": [
        "#**Random Forest Regressor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GY5GHxiG0BV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Random Forest Regressor\n",
        "clf = RandomForestRegressor(n_estimators=991, criterion='mse', max_depth=10, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=False, oob_score=False, n_jobs=-1, random_state=500, verbose=0, warm_start=False)\n",
        "clf.fit(train_sample, train_label)\n",
        "\n",
        "predsRf_test = clf.predict(test_sample)\n",
        "#print(clf.score(X_train, y_train))\n",
        "\n",
        "r2_rf = r2_score(test_label, predsRf_test, sample_weight=None, multioutput='uniform_average')\n",
        "print(\"R_Squared_Prediction: \", r2_rf)\n",
        "mse_rf_test= mean_squared_error(test_label.ravel(), predsRf_test.ravel())\n",
        "rmsep = np.sqrt(mse_rf_test)\n",
        "print(\"RMSEP:\", rmsep)\n",
        "\n",
        "predsRf_train = clf.predict(train_sample)\n",
        "mse_rf_train= mean_squared_error(train_label.ravel(), predsRf_train.ravel())\n",
        "rmset = np.sqrt(mse_rf_train)\n",
        "print(\"RMSET:\", rmset)\n",
        "\n",
        "param_range = list(range(1, 1000,10))\n",
        "estimator = RandomForestRegressor()\n",
        "estimator_name = \"Random Forest Regressor(n_estimators)\\n\"\n",
        "validate_estimator(train_sample,train_label,estimator,estimator_name,\"n_estimators\",param_range, \"Number of Estimators\")\n",
        "\n",
        "train_score = clf.score(train_sample, train_label)\n",
        "test_score = clf.score(test_sample, test_label)\n",
        "print(\"R2_T/Train_Score:\", train_score)\n",
        "print(\"R2_P/Test_Score:\", test_score)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPop08BSaCn8",
        "colab_type": "text"
      },
      "source": [
        "#**K-Nearest Neighbors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iByhUPUpuvMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#KNeighbors Regressor\n",
        "\n",
        "##METRIC:\n",
        "#euclidean\n",
        "#manhattan\n",
        "#hamming\n",
        "#minkowski\n",
        "\n",
        "knn = KNeighborsRegressor(n_neighbors=4, weights='uniform', algorithm='auto', leaf_size=1, p=2, metric='manhattan', metric_params=None, n_jobs=-1)\n",
        "knn.fit(train_sample, train_label)\n",
        "predsKNN_test = knn.predict(test_sample)\n",
        "predsKNN_train = knn.predict(train_sample)\n",
        "\n",
        "scores_cv = cross_validate(knn, train_sample, train_label, groups=None, scoring=('r2','neg_mean_squared_error'), cv=10, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=True, return_estimator=False)\n",
        "#print(np.mean(list(scores_cv.values())))\n",
        "#print(scores_cv['test_neg_mean_squared_error'].mean())\n",
        "#print(scores_cv['train_r2'].mean())\n",
        "\n",
        "r2_knn = r2_score(test_label, predsKNN_test, sample_weight=None, multioutput='uniform_average')\n",
        "print(\"R_Squared_Prediction: \", r2_knn)\n",
        "mse_KNN_test= mean_squared_error(test_label.ravel(), predsKNN_test.ravel())\n",
        "rmsep = np.sqrt(mse_KNN_test)\n",
        "print(\"RMSEP:\", rmsep)\n",
        "\n",
        "mse_knn_train= mean_squared_error(train_label.ravel(), predsKNN_train.ravel())\n",
        "rmset = np.sqrt(mse_knn_train)\n",
        "print(\"RMSET:\", rmset)\n",
        "\n",
        "param_range = list(range(1, 18,3))\n",
        "estimator = KNeighborsRegressor()\n",
        "estimator_name = \"K-Nearest Neighbors Regressor(n_neighbors)\\n\"\n",
        "validate_estimator (train_sample,train_label,estimator, estimator_name,\"n_neighbors\",param_range, \"Number of Neighbors\")\n",
        "\n",
        "train_score = knn.score(train_sample, train_label)\n",
        "test_score = knn.score(test_sample, test_label)\n",
        "print(\"R2_T/Train_Score:\", train_score)\n",
        "print(\"R2_P/Test_Score:\", test_score)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHNOPDR8aKaa",
        "colab_type": "text"
      },
      "source": [
        "#**Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jByE3EKq79ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Decision Tree\n",
        "\n",
        "dct = DecisionTreeRegressor(criterion='mse', splitter='best', max_depth=6, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, presort='deprecated', ccp_alpha=0.0)\n",
        "dct.fit(train_sample, train_label)\n",
        "predTree_test = dct.predict(test_sample)\n",
        "\n",
        "predTree_train = dct.predict(train_sample)\n",
        "r2_dct = r2_score(test_label, predTree_test, sample_weight=None, multioutput='uniform_average')\n",
        "print(\"R_Squared_Prediction: \", r2_dct)\n",
        "mse_tree_test= mean_squared_error(test_label.ravel(), predTree_test.ravel())\n",
        "rmsep = np.sqrt(mse_tree_test)\n",
        "print(\"RMSEP:\", rmsep)\n",
        "\n",
        "mse_tree_T= mean_squared_error(train_label.ravel(), predTree_train.ravel())\n",
        "rmset = np.sqrt(mse_tree_T)\n",
        "print(\"RMSET:\", rmset)\n",
        "\n",
        "param_range = list(range(1, 100,10))\n",
        "#param_range = np.logspace(-6, -1, 5)\n",
        "estimator = DecisionTreeRegressor()\n",
        "estimator_name = \"Decision Tree Regressor(max_depth) \\n\"\n",
        "validate_estimator (train_sample,train_label,estimator,estimator_name,\"max_depth\",param_range, \"Max Depth\")\n",
        "\n",
        "train_score = dct.score(train_sample, train_label)\n",
        "test_score = dct.score(test_sample, test_label)\n",
        "print(\"R2_train/Train_Score:\", train_score)\n",
        "print(\"R2_test/Test_Score:\", test_score)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GO4yRD_aPGC",
        "colab_type": "text"
      },
      "source": [
        "#**Support Vector Machine**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHs5U5lJ--5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "# training using 'training data'\n",
        "sv_reg = SVR(kernel='rbf', degree=3, gamma=0.03, coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
        "sv_reg.fit(train_sample, train_label) # fit the model for training data\n",
        "# predict the 'target' for 'test data'\n",
        "predsSVR_test = sv_reg.predict(test_sample)\n",
        "\n",
        "scores_cv = cross_validate(sv_reg, train_sample, train_label, groups=None, scoring=('r2','neg_mean_squared_error'), cv=10, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=True, return_estimator=False)\n",
        "#print(np.mean(list(scores_cv.values())))\n",
        "#print(scores_cv['test_neg_mean_squared_error'].mean())\n",
        "#print(scores_cv['train_r2'].mean())\n",
        "\n",
        "predsSVR_train = sv_reg.predict(train_sample)\n",
        "r2_svr = r2_score(test_label, predsSVR_test, sample_weight=None, multioutput='uniform_average')\n",
        "print(\"R_Squared_Prediction: \", r2_svr)\n",
        "mse_SVR_test= mean_squared_error(test_label.ravel(), predsSVR_test.ravel())\n",
        "rmsep = np.sqrt(mse_SVR_test)\n",
        "print(\"RMSEP:\", rmsep)\n",
        "\n",
        "mse_SVR_T= mean_squared_error(train_label.ravel(), predsSVR_train.ravel())\n",
        "rmset = np.sqrt(mse_SVR_T)\n",
        "print(\"RMSET:\", rmset)\n",
        "\n",
        "test_accuracy = sv_reg.score(test_sample, test_label)\n",
        "print(\"Accuracy for test data:\", test_accuracy)\n",
        "\n",
        "#param_range = list(range(1, 18,3))\n",
        "param_range = np.logspace(-6, -1, 5)\n",
        "estimator = SVR()\n",
        "estimator_name = \"SVM (Regression - gamma)\\n\"\n",
        "validate_estimator (train_sample,train_label,estimator,estimator_name,\"gamma\",param_range, \"Gamma\")\n",
        "\n",
        "train_score = sv_reg.score(train_sample, train_label)\n",
        "test_score = sv_reg.score(test_sample, test_label)\n",
        "print(\"R2_T/Train_Score:\", train_score)\n",
        "print(\"R2_P/Test_Score:\", test_score)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I7gYYNsAz8n",
        "colab_type": "text"
      },
      "source": [
        "#**Partial Least Square Regression (PLSR)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w91GL857A2C1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plsr = PLSRegression(n_components=30, scale=True, max_iter=500, tol=1e-06, copy=True)\n",
        "plsr.fit(train_sample_plsr, train_label_plsr) # fit the model for training data\n",
        "# predict the 'target' for 'test data'\n",
        "predsplsr_test = plsr.predict(test_sample_plsr)\n",
        "\n",
        "scores_cv = cross_validate(plsr, train_sample_plsr, train_label_plsr, groups=None, scoring=('r2','neg_mean_squared_error'), cv=10, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=True, return_estimator=False)\n",
        "#print(np.mean(list(scores_cv.values())))\n",
        "#print(scores_cv['test_neg_mean_squared_error'].mean())\n",
        "#print(scores_cv['train_r2'].mean())\n",
        "\n",
        "predsplsr_train = plsr.predict(train_sample_plsr)\n",
        "r2_plsr = r2_score(test_label_plsr, predsplsr_test, sample_weight=None, multioutput='uniform_average')\n",
        "print(\"R_Squared_Prediction: \", r2_plsr)\n",
        "mse_plsr_test= mean_squared_error(test_label_plsr.ravel(), predsplsr_test.ravel())\n",
        "rmsep = np.sqrt(mse_plsr_test)\n",
        "print(\"RMSEP:\", rmsep)\n",
        "\n",
        "mse_plsr_T= mean_squared_error(train_label_plsr.ravel(), predsplsr_train.ravel())\n",
        "rmset = np.sqrt(mse_plsr_T)\n",
        "print(\"RMSET:\", rmset)\n",
        "\n",
        "test_accuracy = plsr.score(test_sample_plsr, test_label_plsr)\n",
        "print(\"Accuracy for test data:\", test_accuracy)\n",
        "\n",
        "param_range = list(range(2,30,2))\n",
        "#param_range = np.logspace(-6, -1, 5)\n",
        "estimator = plsr\n",
        "estimator_name = \"PLSR (n_components)\\n\"\n",
        "validate_estimator (train_sample,train_label,estimator,estimator_name,\"n_components\",param_range,\"Number of Components\")\n",
        "\n",
        "train_score = plsr.score(train_sample_plsr, train_label_plsr)\n",
        "test_score = plsr.score(test_sample_plsr, test_label_plsr)\n",
        "print(\"R2_T/Train_Score:\", train_score)\n",
        "print(\"R2_P/Test_Score:\", test_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fpz_ktwaUce",
        "colab_type": "text"
      },
      "source": [
        "#**Ensemble Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WLI9LkHJH-v-",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import VotingRegressor\n",
        "model1 = clf\n",
        "model2 = knn\n",
        "model3 = dct\n",
        "model4 = sv_reg\n",
        "model5 = plsr\n",
        "\n",
        "model = VotingRegressor(estimators=[('rf', model1), ('kn', model2), ('dc', model3), ('sv', model4), ('pl', model5)], weights=None, n_jobs=None)\n",
        "model.fit(train_sample,train_label)\n",
        "model.score(test_sample,test_label)\n",
        "preds_test = model.predict(test_sample)\n",
        "\n",
        "r2_voting = r2_score(test_label, preds_test, sample_weight=None, multioutput='uniform_average')\n",
        "print(\"R_Squared_Prediction: \", r2_voting)\n",
        "mse_voting_test= mean_squared_error(test_label.ravel(), preds_test.ravel())\n",
        "rmsep = np.sqrt(mse_voting_test)\n",
        "print(\"RMSEP:\", rmsep)\n",
        "\n",
        "preds_train = model.predict(train_sample)\n",
        "mse_voting_training= mean_squared_error(train_label.ravel(), preds_train.ravel())\n",
        "rmset = np.sqrt(mse_voting_training)\n",
        "print(\"RMSET:\", rmset)\n",
        "\n",
        "train_score = model.score(train_sample, train_label)\n",
        "test_score = model.score(test_sample, test_label)\n",
        "print(\"R2_T/Train_Score:\", train_score)\n",
        "print(\"R2_P/Test_Score:\", test_score)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}